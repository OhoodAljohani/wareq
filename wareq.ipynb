{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Start here ","metadata":{}},{"cell_type":"code","source":"import keras\nimport tensorflow as tf\nfrom keras.layers.pooling import GlobalAveragePooling1D\nimport pandas as pd\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Conv2D, Convolution2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras.layers import Activation, Dense\nfrom sklearn.model_selection import train_test_split\n","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:04:40.677008Z","iopub.execute_input":"2022-05-23T21:04:40.677468Z","iopub.status.idle":"2022-05-23T21:04:46.979721Z","shell.execute_reply.started":"2022-05-23T21:04:40.677385Z","shell.execute_reply":"2022-05-23T21:04:46.978856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data : ","metadata":{}},{"cell_type":"code","source":"data_path = \"../input/plants-100/\"\ndata_gen = ImageDataGenerator(rescale=1./255,  validation_split=0.10)\ntrain_data = data_gen.flow_from_directory(directory=data_path,target_size=(224, 224), batch_size=32, subset='training', seed=42, class_mode='categorical' ,shuffle=False ) \ntest_data = data_gen.flow_from_directory(directory=data_path,target_size=(224, 224), batch_size=32, subset='validation', seed=42, class_mode='categorical',shuffle=False ) ","metadata":{"execution":{"iopub.status.busy":"2022-05-23T21:04:46.981357Z","iopub.execute_input":"2022-05-23T21:04:46.981603Z","iopub.status.idle":"2022-05-23T21:04:50.206432Z","shell.execute_reply.started":"2022-05-23T21:04:46.981568Z","shell.execute_reply":"2022-05-23T21:04:50.205682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data.class_indices)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-22T20:34:37.886824Z","iopub.execute_input":"2022-05-22T20:34:37.887291Z","iopub.status.idle":"2022-05-22T20:34:37.895321Z","shell.execute_reply.started":"2022-05-22T20:34:37.887253Z","shell.execute_reply":"2022-05-22T20:34:37.891241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model : ","metadata":{}},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D,Conv3D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nimage_size = (224,224)\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=image_size + (3,) )\nbn = []\nfor layer in base_model.layers:\n    bn.append(layer)\nmodel = Sequential(bn)\nmodel.add(Conv2D(32, (3, 3), activation='relu',padding='same', input_shape=(32, 32, 3)))\nmodel.add(MaxPooling2D())\nmodel.add(Conv2D(64, (3, 3), activation='relu',padding='same'))\nmodel.add(MaxPooling2D())\nmodel.add(Conv2D(64, (3, 3), activation='relu',padding='same'))\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(100, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-05-22T16:14:20.77671Z","iopub.execute_input":"2022-05-22T16:14:20.777491Z","iopub.status.idle":"2022-05-22T16:14:24.365057Z","shell.execute_reply.started":"2022-05-22T16:14:20.77744Z","shell.execute_reply":"2022-05-22T16:14:24.364277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Compile :","metadata":{}},{"cell_type":"code","source":"model.compile(\n    optimizer=tf.optimizers.Adam(1e-06),\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"],\n    \n)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T16:14:30.385488Z","iopub.execute_input":"2022-05-22T16:14:30.386225Z","iopub.status.idle":"2022-05-22T16:14:30.404022Z","shell.execute_reply.started":"2022-05-22T16:14:30.386187Z","shell.execute_reply":"2022-05-22T16:14:30.403307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fit :","metadata":{}},{"cell_type":"code","source":"from sklearn.utils import class_weight \nimport numpy as np\n\nclass_weights = class_weight.compute_class_weight(\n    class_weight= \"balanced\",\n            classes = np.unique(train_data.classes), \n            y=train_data.classes)\n\ntrain_class_weights = dict(enumerate(class_weights))","metadata":{"execution":{"iopub.status.busy":"2022-05-22T20:44:29.436157Z","iopub.execute_input":"2022-05-22T20:44:29.436743Z","iopub.status.idle":"2022-05-22T20:44:29.45362Z","shell.execute_reply.started":"2022-05-22T20:44:29.436701Z","shell.execute_reply":"2022-05-22T20:44:29.452937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h = model.fit(train_data, \n              epochs=10, \n              validation_data = test_data,\n              class_weight = train_class_weights\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T20:45:17.149454Z","iopub.execute_input":"2022-05-22T20:45:17.149738Z","iopub.status.idle":"2022-05-22T21:28:40.164593Z","shell.execute_reply.started":"2022-05-22T20:45:17.149707Z","shell.execute_reply":"2022-05-22T21:28:40.16373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Save :","metadata":{}},{"cell_type":"code","source":"model.save('mymodel97.h5',save_format='h5')\n","metadata":{"execution":{"iopub.status.busy":"2022-05-22T21:30:10.907323Z","iopub.execute_input":"2022-05-22T21:30:10.907997Z","iopub.status.idle":"2022-05-22T21:30:11.22876Z","shell.execute_reply.started":"2022-05-22T21:30:10.907953Z","shell.execute_reply":"2022-05-22T21:30:11.227689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load : ","metadata":{}},{"cell_type":"code","source":"from tensorflow import keras\nmodel = keras.models.load_model('../input/mymodel2/mymodel.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Predict : ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimage_size = (224,224)\n#model.summary()\n# #Predict model\nimg = keras.preprocessing.image.load_img(\n\"../input/plants-100/11/dr_0_1025.jpeg\", target_size=image_size\n)\nimg_array = keras.preprocessing.image.img_to_array(img)/255\nimg_array = tf.expand_dims(img_array, 0)  # Create batch axis\npredictions = model.predict(img_array)\noutput=np.argmax(predictions,axis=1)\nclasses = {'0': 0, '1': 1, '10': 2, '11': 3, '12': 4, '13': 5, '14': 6,\\\n '15': 7, '16': 8, '17': 9, '18': 10, '19': 11, '2': 12, '20': 13,\\\n'21': 14, '22': 15, '23': 16, '24': 17, '25': 18, '26': 19,\\\n'27': 20, '28': 21, '29': 22, '3': 23, '30': 24, '31': 25,\\\n'32': 26, '33': 27, '34': 28, '35': 29, '36': 30, '37': 31,\\\n'38': 32, '39': 33, '4': 34, '40': 35, '41': 36, '42': 37,\\\n'43': 38, '44': 39, '45': 40, '46': 41, '47': 42, '48': 43,\\\n'49': 44, '5': 45, '50': 46, '51': 47, '52': 48,\\\n'53': 49, '54': 50, '55': 51, '56': 52,\\\n'57': 53, '58': 54, '59': 55,\\\n'6': 56, '60': 57, '61': 58, '62': 59, \\\n'63': 60, '64': 61, '65': 62, '66': 63,\\\n'67': 64, '68': 65, '69': 66, '7': 67,\\\n'70': 68, '71': 69, '72': 70, '73': 71, '74': 72,\\\n'75': 73, '76': 74, '77': 75, '78': 76, '79': 77, '8': 78,\\\n'80': 79, '81': 80, '82': 81, '83': 82, '84': 83, '85': 84,\\\n'86': 85, '87': 86, '88': 87, '89': 88, '9': 89, '90': 90, '91': 91,\\\n'92': 92, '93': 93, '94': 94, '95': 95, '96': 96, '97': 97, '98': 98, '99': 99}\nclasses = dict((v,k) for k,v in classes.items())\n","metadata":{"execution":{"iopub.status.busy":"2022-05-22T22:26:47.742092Z","iopub.execute_input":"2022-05-22T22:26:47.742352Z","iopub.status.idle":"2022-05-22T22:26:47.807116Z","shell.execute_reply.started":"2022-05-22T22:26:47.742323Z","shell.execute_reply":"2022-05-22T22:26:47.806375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = np.array_str(output)\nprint(type(result))\nr = result.lstrip(\"[\").rstrip(\"]\")\nresult = int(r)\nr = classes[result]\nprint(\"The images is predicted : \",r)\nprint(\n     \"This image is predicted as \",output\n )","metadata":{"execution":{"iopub.status.busy":"2022-05-22T22:26:50.591504Z","iopub.execute_input":"2022-05-22T22:26:50.592001Z","iopub.status.idle":"2022-05-22T22:26:50.599999Z","shell.execute_reply.started":"2022-05-22T22:26:50.591954Z","shell.execute_reply":"2022-05-22T22:26:50.599281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"{'0': 0, '1': 1, '10': 2, '11': 3, '12': 4, '13': 5, '14': 6, '15': 7, '16': 8, '17': 9, '18': 10, '19': 11, '2': 12, '20': 13, '21': 14, '22': 15, '23': 16, '24': 17, '25': 18, '26': 19, '27': 20, '28': 21, '29': 22, '3': 23, '30': 24, '31': 25, '32': 26, '33': 27, '34': 28, '35': 29, '36': 30, '37': 31, '38': 32, '39': 33, '4': 34, '40': 35, '41': 36, '42': 37, '43': 38, '44': 39, '45': 40, '46': 41, '47': 42, '48': 43, '49': 44, '5': 45, '50': 46, '51': 47, '52': 48, '53': 49, '54': 50, '55': 51, '56': 52, '57': 53, '58': 54, '59': 55, '6': 56, '60': 57, '61': 58, '62': 59, '63': 60, '64': 61, '65': 62, '66': 63, '67': 64, '68': 65, '69': 66, '7': 67, '70': 68, '71': 69, '72': 70, '73': 71, '74': 72, '75': 73, '76': 74, '77': 75, '78': 76, '79': 77, '8': 78, '80': 79, '81': 80, '82': 81, '83': 82, '84': 83, '85': 84, '86': 85, '87': 86, '88': 87, '89': 88, '9': 89, '90': 90, '91': 91, '92': 92, '93': 93, '94': 94, '95': 95, '96': 96, '97': 97, '98': 98, '99': 99}","metadata":{}},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-05-22T22:02:07.786592Z","iopub.execute_input":"2022-05-22T22:02:07.786857Z","iopub.status.idle":"2022-05-22T22:02:07.792284Z","shell.execute_reply.started":"2022-05-22T22:02:07.786828Z","shell.execute_reply":"2022-05-22T22:02:07.791516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nimport tensorflow as tf\nfrom keras.layers.pooling import GlobalAveragePooling1D\nimport pandas as pd\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Conv2D, Convolution2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras.layers import Activation, Dense\nfrom sklearn.model_selection import train_test_split\n","metadata":{"execution":{"iopub.status.busy":"2022-05-20T18:32:51.699838Z","iopub.execute_input":"2022-05-20T18:32:51.700266Z","iopub.status.idle":"2022-05-20T18:33:00.507479Z","shell.execute_reply.started":"2022-05-20T18:32:51.700159Z","shell.execute_reply":"2022-05-20T18:33:00.506721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_size = (100, 100)\nbatch_size = 64\nfrom tensorflow.keras import layers\ndef make_model(input_shape, num_classes):\n    inputs = keras.Input(shape=input_shape)\n    # Image augmentation block\n    data_augmentation = keras.Sequential(\n    [\n        layers.RandomFlip(\"horizontal\"),\n        layers.RandomRotation(0.1),\n    ])\n    x = data_augmentation(inputs)\n\n    # Entry block\n    x = layers.Rescaling(1.0 / 255)(x)\n    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    previous_block_activation = x  # Set aside residual\n\n    for size in [128, 256, 512, 728]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n\n        # Project residual\n        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n            previous_block_activation\n        )\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    x = layers.GlobalAveragePooling2D()(x)\n    if num_classes == 2:\n        activation = \"sigmoid\"\n        units = 1\n    else:\n        activation = \"softmax\"\n        units = num_classes\n\n    #x = layers.Dropout(0.5)(x)\n    outputs = layers.Dense(units, activation=activation)(x)\n    return keras.Model(inputs, outputs)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-19T10:03:01.81374Z","iopub.execute_input":"2022-05-19T10:03:01.813996Z","iopub.status.idle":"2022-05-19T10:03:01.828118Z","shell.execute_reply.started":"2022-05-19T10:03:01.81396Z","shell.execute_reply":"2022-05-19T10:03:01.827478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_path = \"../input/plants-100/\"\ndata_gen = ImageDataGenerator(rescale=1./255,  validation_split=0.30)#30\ntrain_data = data_gen.flow_from_directory(directory=data_path,target_size=(256, 256), batch_size=32, subset='training', seed=42, class_mode='categorical' ,shuffle=False ) \ntest_data = data_gen.flow_from_directory(directory=data_path,target_size=(256, 256), batch_size=32, subset='validation', seed=42, class_mode='categorical',shuffle=False ) ","metadata":{"execution":{"iopub.status.busy":"2022-05-20T18:33:00.508894Z","iopub.execute_input":"2022-05-20T18:33:00.509248Z","iopub.status.idle":"2022-05-20T18:33:03.60252Z","shell.execute_reply.started":"2022-05-20T18:33:00.509218Z","shell.execute_reply":"2022-05-20T18:33:03.60155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = make_model(input_shape=image_size + (3,), num_classes=100)\nepochs = 10\n","metadata":{"execution":{"iopub.status.busy":"2022-05-19T10:03:15.778358Z","iopub.execute_input":"2022-05-19T10:03:15.77919Z","iopub.status.idle":"2022-05-19T10:03:19.011603Z","shell.execute_reply.started":"2022-05-19T10:03:15.779151Z","shell.execute_reply":"2022-05-19T10:03:19.010831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [\n    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n]\n","metadata":{"execution":{"iopub.status.busy":"2022-05-19T10:03:22.098374Z","iopub.execute_input":"2022-05-19T10:03:22.098729Z","iopub.status.idle":"2022-05-19T10:03:22.107006Z","shell.execute_reply.started":"2022-05-19T10:03:22.098669Z","shell.execute_reply":"2022-05-19T10:03:22.105644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer=tf.optimizers.Adam(1e-06),\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"],\n    \n)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-18T14:21:17.680714Z","iopub.execute_input":"2022-05-18T14:21:17.681387Z","iopub.status.idle":"2022-05-18T14:21:17.695086Z","shell.execute_reply.started":"2022-05-18T14:21:17.681351Z","shell.execute_reply":"2022-05-18T14:21:17.694396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h = model.fit(\n    train_data, epochs=epochs, callbacks=callbacks, validation_data= test_data\n)\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-18T14:21:20.275859Z","iopub.execute_input":"2022-05-18T14:21:20.276145Z","iopub.status.idle":"2022-05-18T15:19:36.416864Z","shell.execute_reply.started":"2022-05-18T14:21:20.276106Z","shell.execute_reply":"2022-05-18T15:19:36.416084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"./\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('mymodel.h5',save_format='h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-18T15:19:53.061835Z","iopub.execute_input":"2022-05-18T15:19:53.062093Z","iopub.status.idle":"2022-05-18T15:19:53.282401Z","shell.execute_reply.started":"2022-05-18T15:19:53.062064Z","shell.execute_reply":"2022-05-18T15:19:53.281586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"execution":{"iopub.status.busy":"2022-05-19T10:03:47.198652Z","iopub.execute_input":"2022-05-19T10:03:47.19939Z","iopub.status.idle":"2022-05-19T10:03:48.536737Z","shell.execute_reply.started":"2022-05-19T10:03:47.199356Z","shell.execute_reply":"2022-05-19T10:03:48.535981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nimport numpy as np\nimport tensorflow as tf\nmodel = keras.models.load_model('mymodel.h5')\n# # Check its architecture\nimage_size = (180,180)\n#model.summary()\n# #Predict model\nimg = keras.preprocessing.image.load_img(\n\"../input/plants/images/120/dr_0_1013.jpeg\", target_size=image_size\n)\nimg_array = keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create batch axis\npredictions = model.predict(img_array)\noutput=np.argmax(predictions,axis=1)\n\nprint(\n     \"This image is predicted as \",output\n )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_path = \"../input/plants-100\"\ndata_gen2 = ImageDataGenerator(rescale=1./255,  validation_split=0.25)\ntrain_data2 = data_gen2.flow_from_directory(directory=data_path,target_size=(224, 224), batch_size=32, subset='training', seed=42, class_mode='categorical'  ) \ntest_data2 = data_gen2.flow_from_directory(directory=data_path,target_size=(224, 224), batch_size=32, subset='validation', seed=42, class_mode='categorical' ) ","metadata":{"execution":{"iopub.status.busy":"2022-05-22T12:50:59.853361Z","iopub.execute_input":"2022-05-22T12:50:59.853635Z","iopub.status.idle":"2022-05-22T12:51:02.435249Z","shell.execute_reply.started":"2022-05-22T12:50:59.853604Z","shell.execute_reply":"2022-05-22T12:51:02.434379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h = model.fit(\n    train_data2, epochs=5, validation_data= test_data2,\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-22T12:51:32.283832Z","iopub.execute_input":"2022-05-22T12:51:32.284117Z","iopub.status.idle":"2022-05-22T13:04:05.31561Z","shell.execute_reply.started":"2022-05-22T12:51:32.284085Z","shell.execute_reply":"2022-05-22T13:04:05.313982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('mymodel96.h5',save_format='h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:00:18.949007Z","iopub.execute_input":"2022-05-19T11:00:18.949653Z","iopub.status.idle":"2022-05-19T11:00:19.180265Z","shell.execute_reply.started":"2022-05-19T11:00:18.94961Z","shell.execute_reply":"2022-05-19T11:00:19.179443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nmodel = keras.models.load_model('./mymodel96.h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:00:35.358214Z","iopub.execute_input":"2022-05-19T11:00:35.35908Z","iopub.status.idle":"2022-05-19T11:00:36.207561Z","shell.execute_reply.started":"2022-05-19T11:00:35.359046Z","shell.execute_reply":"2022-05-19T11:00:36.206825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''from tensorflow import keras\nimport numpy as np\nimport tensorflow as tf\nmodel = keras.models.load_model('mymodel.h5')'''\n# # Check its architecture\nimport numpy as np\nimage_size = (100,100)\n#model.summary()\n# #Predict model\nimg = keras.preprocessing.image.load_img(\n\"../input/plants-100/0/dr_0_1025.jpeg\", target_size=image_size\n)\nimg_array = keras.preprocessing.image.img_to_array(img)/255\nimg_array = tf.expand_dims(img_array, 0)  # Create batch axis\npredictions = model.predict(img_array)\noutput=np.argmax(predictions,axis=1)\n\nprint(\n     \"This image is predicted as \",output\n )","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:00:41.468195Z","iopub.execute_input":"2022-05-19T11:00:41.468865Z","iopub.status.idle":"2022-05-19T11:00:41.856951Z","shell.execute_reply.started":"2022-05-19T11:00:41.468829Z","shell.execute_reply":"2022-05-19T11:00:41.856169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_size = (100,100)\nimg = keras.preprocessing.image.load_img(\n\"../input/plants/images/120/dr_0_1013.jpeg\", target_size=image_size\n)\nimg_array = keras.preprocessing.image.img_to_array(img)/255.0\nimg_array = tf.expand_dims(img_array, 0)  # Create batch axis\npredictions = model.predict(img_array)\noutput=np.argmax(predictions,axis=1)\n\nprint(\n     \"This image is predicted as \",output\n )","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:04:00.238764Z","iopub.execute_input":"2022-05-19T11:04:00.239025Z","iopub.status.idle":"2022-05-19T11:04:00.289368Z","shell.execute_reply.started":"2022-05-19T11:04:00.238998Z","shell.execute_reply":"2022-05-19T11:04:00.288648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h = model.fit(\n    train_data, epochs=50,  validation_data= test_data,\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T15:21:11.420484Z","iopub.execute_input":"2022-05-18T15:21:11.421167Z","iopub.status.idle":"2022-05-18T20:09:14.164235Z","shell.execute_reply.started":"2022-05-18T15:21:11.421131Z","shell.execute_reply":"2022-05-18T20:09:14.163481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('mymodel94.h5',save_format='h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-18T22:32:22.042017Z","iopub.execute_input":"2022-05-18T22:32:22.042742Z","iopub.status.idle":"2022-05-18T22:32:22.298245Z","shell.execute_reply.started":"2022-05-18T22:32:22.042691Z","shell.execute_reply":"2022-05-18T22:32:22.297429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''from tensorflow import keras\nimport numpy as np\nimport tensorflow as tf\nmodel = keras.models.load_model('mymodel.h5')'''\n# # Check its architecture\nimport numpy as np\nimage_size = (100,100)\n#model.summary()\n# #Predict model\nimg = keras.preprocessing.image.load_img(\n\"../input/plants-100/0/dr_0_1025.jpeg\", target_size=image_size\n)\nimg_array = keras.preprocessing.image.img_to_array(img)/255\nimg_array = tf.expand_dims(img_array, 0)  # Create batch axis\npredictions = model.predict(img_array)\noutput=np.argmax(predictions,axis=1)\n\nprint(\n     \"This image is predicted as \",output\n )","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:03:18.949213Z","iopub.execute_input":"2022-05-19T11:03:18.949487Z","iopub.status.idle":"2022-05-19T11:03:19.007068Z","shell.execute_reply.started":"2022-05-19T11:03:18.949457Z","shell.execute_reply":"2022-05-19T11:03:19.006272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = keras.preprocessing.image.load_img(\n\"../input/plants-100/12/dr_0_1019.jpeg\", target_size=image_size\n)\nimg_array = keras.preprocessing.image.img_to_array(img)/255\nimg_array = tf.expand_dims(img_array, 0)  # Create batch axis\npredictions = model.predict(img_array)\noutput=np.argmax(predictions,axis=1)\n\nprint(\n     \"This image is predicted as \",output\n )","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:03:26.748706Z","iopub.execute_input":"2022-05-19T11:03:26.749166Z","iopub.status.idle":"2022-05-19T11:03:26.796497Z","shell.execute_reply.started":"2022-05-19T11:03:26.749135Z","shell.execute_reply":"2022-05-19T11:03:26.795743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = keras.preprocessing.image.load_img(\n\"../input/plants-100/1/dr_0_1026.jpeg\", target_size=image_size\n)\n\n\nimg_array = keras.preprocessing.image.img_to_array(img)/255\nimg_array = tf.expand_dims(img_array, 0)  # Create batch axis\npredictions = model.predict(img_array)\noutput=np.argmax(predictions,axis=1)\n\nprint(\n     \"This image is predicted as \",output\n )","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:03:34.748607Z","iopub.execute_input":"2022-05-19T11:03:34.74931Z","iopub.status.idle":"2022-05-19T11:03:34.796804Z","shell.execute_reply.started":"2022-05-19T11:03:34.749275Z","shell.execute_reply":"2022-05-19T11:03:34.796053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = keras.preprocessing.image.load_img(\n\"../input/plants-100/20/dr_0_1030.jpeg\", target_size=image_size\n)\nimg_array = keras.preprocessing.image.img_to_array(img)/255\nimg_array = tf.expand_dims(img_array, 0)  # Create batch axis\npredictions = model.predict(img_array)\noutput=np.argmax(predictions,axis=1)\n\nprint(\n     \"This image is predicted as \",output\n )","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:04:15.739123Z","iopub.execute_input":"2022-05-19T11:04:15.739878Z","iopub.status.idle":"2022-05-19T11:04:15.788605Z","shell.execute_reply.started":"2022-05-19T11:04:15.739829Z","shell.execute_reply":"2022-05-19T11:04:15.787854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = keras.preprocessing.image.load_img(\n\"../input/plant2/images - Copy/1/image2_4.jpeg\", target_size=image_size\n)\nimg_array = keras.preprocessing.image.img_to_array(img)/255\nimg_array = tf.expand_dims(img_array, 0)  # Create batch axis\npredictions = model.predict(img_array)\noutput=np.argmax(predictions,axis=1)\n\nprint(\n     \"This image is predicted as \",output\n )","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:07:27.604737Z","iopub.execute_input":"2022-05-19T11:07:27.605265Z","iopub.status.idle":"2022-05-19T11:07:27.659317Z","shell.execute_reply.started":"2022-05-19T11:07:27.605227Z","shell.execute_reply":"2022-05-19T11:07:27.658577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = keras.preprocessing.image.load_img(\n\"../input/plants-100/10/dr_0_8132.jpeg\", target_size=image_size\n)\nimg_array = keras.preprocessing.image.img_to_array(img)/255\nimg_array = tf.expand_dims(img_array, 0)  # Create batch axis\npredictions = model.predict(img_array)\noutput=np.argmax(predictions,axis=1)\n\nprint(\n     \"This image is predicted as \",output\n )\ny_classes = predictions.argmax(axis=-1)\nprint(y_classes)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:04:30.989426Z","iopub.execute_input":"2022-05-19T11:04:30.989975Z","iopub.status.idle":"2022-05-19T11:04:31.037319Z","shell.execute_reply.started":"2022-05-19T11:04:30.989937Z","shell.execute_reply":"2022-05-19T11:04:31.036619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T11:04:38.599107Z","iopub.execute_input":"2022-05-19T11:04:38.599385Z","iopub.status.idle":"2022-05-19T11:05:11.377764Z","shell.execute_reply.started":"2022-05-19T11:04:38.599355Z","shell.execute_reply":"2022-05-19T11:05:11.377056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nmodel = keras.models.load_model('./mymodel94.h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-18T22:35:33.867682Z","iopub.execute_input":"2022-05-18T22:35:33.868153Z","iopub.status.idle":"2022-05-18T22:35:34.535384Z","shell.execute_reply.started":"2022-05-18T22:35:33.868114Z","shell.execute_reply":"2022-05-18T22:35:34.534627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h = model.fit(\n    train_data, epochs=5,  validation_data= test_data,callbacks = callbacks\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T22:03:08.591769Z","iopub.execute_input":"2022-05-18T22:03:08.592684Z","iopub.status.idle":"2022-05-18T22:31:59.635972Z","shell.execute_reply.started":"2022-05-18T22:03:08.592646Z","shell.execute_reply":"2022-05-18T22:31:59.635138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_classes = y_prob.argmax(axis=-1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D,Conv3D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nimage_size = (256,256)\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=image_size + (3,) )\nbn = []\nfor layer in base_model.layers:\n    bn.append(layer)\nmodel = Sequential(bn)\nmodel.add(Conv2D(16, 3, padding='same', activation='relu'))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(16, 3, padding='same', activation='relu'))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(16, 3, padding='same', activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))\nmodel.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(100))\nmodel.add(Activation('softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-05-22T12:30:45.814133Z","iopub.execute_input":"2022-05-22T12:30:45.814542Z","iopub.status.idle":"2022-05-22T12:30:55.098009Z","shell.execute_reply.started":"2022-05-22T12:30:45.814439Z","shell.execute_reply":"2022-05-22T12:30:55.097288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-22T12:31:01.305149Z","iopub.execute_input":"2022-05-22T12:31:01.305778Z","iopub.status.idle":"2022-05-22T12:31:01.329354Z","shell.execute_reply.started":"2022-05-22T12:31:01.30571Z","shell.execute_reply":"2022-05-22T12:31:01.32855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom keras_preprocessing.image import ImageDataGenerator\nbatch_size = 32\n# this is the augmentation configuration we will use for training\n# this is the augmentation configuration we will use for testing:\n# only rescaling\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ndata_path = \"../input/plants-100/\"\ndata_gen = ImageDataGenerator(rescale=1./255,  validation_split=0.15)#30\ntrain_data = data_gen.flow_from_directory(directory=data_path,target_size=(256, 256), batch_size=32, subset='training', seed=42, class_mode='categorical' ,shuffle=False ) \ntest_data = data_gen.flow_from_directory(directory=data_path,target_size=(256, 256), batch_size=32, subset='validation', seed=42, class_mode='categorical',shuffle=False )","metadata":{"execution":{"iopub.status.busy":"2022-05-22T12:31:12.685461Z","iopub.execute_input":"2022-05-22T12:31:12.686066Z","iopub.status.idle":"2022-05-22T12:31:23.408483Z","shell.execute_reply.started":"2022-05-22T12:31:12.686008Z","shell.execute_reply":"2022-05-22T12:31:23.4077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.callbacks import EarlyStopping\nmodel.compile(optimizer=tf.optimizers.Adam(), loss=tf.keras.losses.categorical_crossentropy, metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-05-22T12:35:07.695246Z","iopub.execute_input":"2022-05-22T12:35:07.695543Z","iopub.status.idle":"2022-05-22T12:35:07.71225Z","shell.execute_reply.started":"2022-05-22T12:35:07.695506Z","shell.execute_reply":"2022-05-22T12:35:07.711488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(\n        train_data,\n        steps_per_epoch=1000 // batch_size,\n        epochs=10,\n        validation_data=test_data\n        #validation_steps=800 // batch_size\n)\nmodel.save('model100.h5',save_format='h5')  # always save your weights after training or during training\n","metadata":{"execution":{"iopub.status.busy":"2022-05-22T12:46:25.344147Z","iopub.execute_input":"2022-05-22T12:46:25.344474Z","iopub.status.idle":"2022-05-22T12:46:52.847742Z","shell.execute_reply.started":"2022-05-22T12:46:25.344427Z","shell.execute_reply":"2022-05-22T12:46:52.846527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('mymodel99.h5',save_format='h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-20T18:08:41.736896Z","iopub.execute_input":"2022-05-20T18:08:41.737179Z","iopub.status.idle":"2022-05-20T18:08:41.975392Z","shell.execute_reply.started":"2022-05-20T18:08:41.737148Z","shell.execute_reply":"2022-05-20T18:08:41.974633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nimport tensorflow as tf\nimport numpy as np\nimage_size = (256,256)\nimg = keras.preprocessing.image.load_img(\n\"../input/plants-100/10/dr_0_8132.jpeg\", target_size=image_size\n)\nimg_array = keras.preprocessing.image.img_to_array(img)/255\nimg_array = tf.expand_dims(img_array, 0)  # Create batch axis\npredictions = model.predict(img_array)\noutput=np.argmax(predictions,axis=1)\n\nprint(\n     \"This image is predicted as \",output\n )","metadata":{"execution":{"iopub.status.busy":"2022-05-22T12:41:58.204212Z","iopub.execute_input":"2022-05-22T12:41:58.20448Z","iopub.status.idle":"2022-05-22T12:41:58.690694Z","shell.execute_reply.started":"2022-05-22T12:41:58.20443Z","shell.execute_reply":"2022-05-22T12:41:58.689883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nimport tensorflow as tf\nimport numpy as np\nimg = keras.preprocessing.image.load_img(\n\"../input/plants-100/10/dr_0_8132.jpeg\", target_size=image_size\n)\nimg_array = keras.preprocessing.image.img_to_array(img)/255\nimg_array = tf.expand_dims(img_array, 0)  # Create batch axis\npredictions = model.predict(img_array)\noutput=np.argmax(predictions,axis=1)\n\nprint(\n     \"This image is predicted as \",output\n )\ny_classes = predictions.argmax(axis=-1)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-22T12:42:09.895424Z","iopub.execute_input":"2022-05-22T12:42:09.89569Z","iopub.status.idle":"2022-05-22T12:42:09.949901Z","shell.execute_reply.started":"2022-05-22T12:42:09.895659Z","shell.execute_reply":"2022-05-22T12:42:09.949109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = keras.preprocessing.image.load_img(\n\"../input/plants-100/20/dr_0_1030.jpeg\", target_size=image_size\n)\nimg_array = keras.preprocessing.image.img_to_array(img)/255\nimg_array = tf.expand_dims(img_array, 0)  # Create batch axis\npredictions = model.predict(img_array)\noutput=np.argmax(predictions,axis=1)\n\nprint(\n     \"This image is predicted as \",output\n )","metadata":{"execution":{"iopub.status.busy":"2022-05-22T12:42:15.773874Z","iopub.execute_input":"2022-05-22T12:42:15.775272Z","iopub.status.idle":"2022-05-22T12:42:15.848579Z","shell.execute_reply.started":"2022-05-22T12:42:15.775196Z","shell.execute_reply":"2022-05-22T12:42:15.847717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = keras.preprocessing.image.load_img(\n\"../input/plants-100/12/dr_0_1019.jpeg\", target_size=image_size\n)\nimg_array = keras.preprocessing.image.img_to_array(img)/255\nimg_array = tf.expand_dims(img_array, 0)  # Create batch axis\npredictions = model.predict(img_array)\noutput=np.argmax(predictions,axis=1)\n\nprint(\n     \"This image is predicted as \",output\n )","metadata":{"execution":{"iopub.status.busy":"2022-05-22T12:42:21.304452Z","iopub.execute_input":"2022-05-22T12:42:21.304727Z","iopub.status.idle":"2022-05-22T12:42:21.362943Z","shell.execute_reply.started":"2022-05-22T12:42:21.304698Z","shell.execute_reply":"2022-05-22T12:42:21.362175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimg = keras.preprocessing.image.load_img(\n\"../input/plants-100/0/dr_0_1025.jpeg\", target_size=image_size\n)\nimg_array = keras.preprocessing.image.img_to_array(img)/255\nimg_array = tf.expand_dims(img_array, 0)  # Create batch axis\npredictions = model.predict(img_array)\noutput=np.argmax(predictions,axis=1)\n\nprint(\n     \"This image is predicted as \",output\n )","metadata":{"execution":{"iopub.status.busy":"2022-05-22T12:42:32.384076Z","iopub.execute_input":"2022-05-22T12:42:32.384542Z","iopub.status.idle":"2022-05-22T12:42:32.444878Z","shell.execute_reply.started":"2022-05-22T12:42:32.384492Z","shell.execute_reply":"2022-05-22T12:42:32.444161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom keras_preprocessing.image import ImageDataGenerator\nbatch_size = 32\n# this is the augmentation configuration we will use for training\n# this is the augmentation configuration we will use for testing:\n# only rescaling\ndata_path = \"../input/plants-100/\"\ndata_gen = ImageDataGenerator(rescale=1./255,  validation_split=0.15)#30\ntrain_data = data_gen.flow_from_directory(directory=data_path,target_size=(256, 256), batch_size=32, subset='training', seed=42, class_mode='categorical' ,shuffle=False ) \ntest_data = data_gen.flow_from_directory(directory=data_path,target_size=(256, 256), batch_size=32, subset='validation', seed=42, class_mode='categorical',shuffle=False )","metadata":{"execution":{"iopub.status.busy":"2022-05-22T12:44:13.583725Z","iopub.execute_input":"2022-05-22T12:44:13.584177Z","iopub.status.idle":"2022-05-22T12:44:16.208842Z","shell.execute_reply.started":"2022-05-22T12:44:13.584131Z","shell.execute_reply":"2022-05-22T12:44:16.208089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D,Conv3D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nimage_size = (200,200)\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=image_size + (3,) )\nbn = []\nfor layer in base_model.layers:\n    bn.append(layer)\nmodel = Sequential(bn)\nmodel.add(Conv2D(32, (3, 3), activation='relu',padding='same', input_shape=(32, 32, 3)))\nmodel.add(MaxPooling2D())\nmodel.add(Conv2D(64, (3, 3), activation='relu',padding='same'))\nmodel.add(MaxPooling2D())\nmodel.add(Conv2D(64, (3, 3), activation='relu',padding='same'))\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(100, activation='softmax'))\n","metadata":{"execution":{"iopub.status.busy":"2022-05-22T12:42:53.954906Z","iopub.execute_input":"2022-05-22T12:42:53.955613Z","iopub.status.idle":"2022-05-22T12:42:54.353504Z","shell.execute_reply.started":"2022-05-22T12:42:53.955574Z","shell.execute_reply":"2022-05-22T12:42:54.352735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nmodel.compile(optimizer=tf.optimizers.Adam(), loss=tf.keras.losses.categorical_crossentropy, metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-05-22T12:44:21.935095Z","iopub.execute_input":"2022-05-22T12:44:21.9354Z","iopub.status.idle":"2022-05-22T12:44:21.952597Z","shell.execute_reply.started":"2022-05-22T12:44:21.935353Z","shell.execute_reply":"2022-05-22T12:44:21.951795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(\n        train_data,\n        #steps_per_epoch=1000 // batch_size,\n        epochs=20,\n        validation_data=test_data\n        #validation_steps=800 // batch_size\n)\nmodel.save('model.h5') ","metadata":{"execution":{"iopub.status.busy":"2022-05-22T12:44:27.985926Z","iopub.execute_input":"2022-05-22T12:44:27.986909Z","iopub.status.idle":"2022-05-22T12:44:29.420143Z","shell.execute_reply.started":"2022-05-22T12:44:27.986863Z","shell.execute_reply":"2022-05-22T12:44:29.419062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}